{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content-based recommendations\n",
    "Emanuel de Jong (495804) - Erik Markvoort (519894)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters\n",
    "these global variables are the index of the movie which the reccomendations will be based on and the number of reccomendations that should be given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "WATCH_LIST = []\n",
    "MOVIE_COUNT = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "these modules will be used to complete the assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Std\n",
    "import re\n",
    "\n",
    "# Local\n",
    "from movie_display import movie_display\n",
    "\n",
    "# Third party\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.core.display import HTML\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from ipywidgets import interact_manual\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the imdbdata JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imdb = pd.read_json(\"dataset/imdbdata.json\")[:50]\n",
    "imdb = pd.read_json(\"dataset/imdbdata.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_vectors = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions\n",
    "the function clean_persons is a repeated process where a list of names is transformed into a string which can be applied for a bag of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_persons(persons):\n",
    "    if isinstance(persons, str):  # Ensure the entry is a string\n",
    "        persons = re.sub(r'\\(.*?\\)', '', persons).strip()\n",
    "        persons = persons.replace(\"N/A\", \"\")\n",
    "        persons = persons.replace(\" \", \"\")\n",
    "        persons = persons.replace(\",\", \" \")\n",
    "        persons = persons.strip()\n",
    "    return persons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actors BoW\n",
    "For features that mostly consist of names a bag of words is applied, this includes actors, writers and directors. stemming is not applied and stopwords are not removed as names should remain unchanged. a bag of words is applied for names, and not a tf-idf since it is expected that a name does not appear more than once per movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_actors_bow():\n",
    "    actorRows = imdb['Actors'].apply(clean_persons)\n",
    "\n",
    "    count_vectorizer = CountVectorizer()\n",
    "    bow_actors = count_vectorizer.fit_transform(actorRows)\n",
    "\n",
    "    feature_vectors['Actors'] = bow_actors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writers BoWs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_writers_bow():\n",
    "    writerRows= imdb['Writer'].apply(clean_persons)\n",
    "    writerRows[0]\n",
    "    count_vectorizer = CountVectorizer()\n",
    "    bow_writer = count_vectorizer.fit_transform(writerRows)\n",
    "\n",
    "    feature_vectors['Writer'] = bow_writer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Director BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_director_bow():\n",
    "    imdb['Director'] = imdb['Director'].apply(clean_persons)\n",
    "    directorRows = imdb[\"Director\"]\n",
    "\n",
    "    count_vectorizer = CountVectorizer()\n",
    "    bow_director = count_vectorizer.fit_transform(directorRows)\n",
    "\n",
    "    feature_vectors['Director'] = bow_director"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Title BoW\n",
    "similar to names, titles are not expected to have repeating words, which motivats a choice for a bag of words. a difference, however is the use of a stopwords filter, as titles are expected to have stopwords such as 'the' often. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_title_bow():\n",
    "    sw = set(stopwords.words(\"english\"))\n",
    "    title_rows = imdb[\"Title\"]\n",
    "\n",
    "    title_sentences = []\n",
    "    for title in title_rows:\n",
    "        title += \" \"\n",
    "        words = re.findall(r\"\\b\\w+(?:\\.\\w+)*(?:'\\w+)?\", title)\n",
    "        title_sentences.append(words)\n",
    "\n",
    "    filtered_titles = []\n",
    "    for words in title_sentences:\n",
    "        filtered = [w for w in words if not w.lower() in sw]\n",
    "        title = \"\"\n",
    "        for word in filtered:\n",
    "            title += word + \" \"\n",
    "        filtered_titles.append(title)\n",
    "    count_vectorizer = CountVectorizer()\n",
    "    bow_title = count_vectorizer.fit_transform(filtered_titles)\n",
    "\n",
    "    feature_vectors['Title'] = bow_title    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot TF-IDF\n",
    "the data for the plot is handled differently, as it is expectd that words can appear more than once, which suggests the use of a tf-idf. stemming and stopwords are also applied since plots are full sentences, if not multiple. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_plot_tf_idf():\n",
    "    sw = set(stopwords.words(\"english\"))\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    plot_rows = imdb[\"Plot\"]\n",
    "\n",
    "    plot_sentences = []\n",
    "    for plot in plot_rows:\n",
    "        plot += \" \"\n",
    "        words = re.findall(r\"\\b\\w+(?:\\.\\w+)*(?:'\\w+)?\", plot)\n",
    "        for i in range(len(words)):\n",
    "            words[i] = stemmer.stem(words[i])\n",
    "        plot_sentences.append(words)\n",
    "\n",
    "    filtered_plots = []\n",
    "    for words in plot_sentences:\n",
    "        filtered = [w for w in words if not w.lower() in sw]\n",
    "        filtered_plots.append(filtered)\n",
    "\n",
    "    tf_idf_vectorizer = TfidfVectorizer()\n",
    "    ids = imdb['imdbId'].tolist()  # Ensure IMDb IDs are in list format\n",
    "    filtered_plot_strings = []\n",
    "\n",
    "    for imdb_id, filtered_plot in zip(ids, filtered_plots):\n",
    "        try:\n",
    "            # Ensure filtered_plot is a single string\n",
    "            if isinstance(filtered_plot, list):\n",
    "                filtered_plot = ' '.join(filtered_plot)\n",
    "            \n",
    "            filtered_plot_strings.append(filtered_plot)\n",
    "            \n",
    "        except ValueError as e:\n",
    "            print(f\"Error with IMDb ID {imdb_id}: {e}\")\n",
    "            pass\n",
    "\n",
    "    td_idf_plots = tf_idf_vectorizer.fit_transform(filtered_plot_strings)\n",
    "\n",
    "    feature_vectors['Plot'] = td_idf_plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the similar movies\n",
    "For every feature, a cosine similarity is made up out the mean of the cosine similarities of all movies in the watch list. Then, for this feature, a ranking is made with the highest similarity first and the lowest last. With a ranking of movies for each feature, the features are merged by combining th ranking list which results into a list of totals of rankings. The top N movies are taken out of the ranking and put into a recommendation list. Movies originally in the watch list are also removed from the recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean(reccomendations):\n",
    "    reccomendation = reccomendations[0]\n",
    "    for i in range(1, len(reccomendations)):\n",
    "        reccomendation += reccomendations[i]\n",
    "    reccomendation /= len(reccomendations)\n",
    "    return reccomendation\n",
    "\n",
    "similar_movies = []\n",
    "\n",
    "def get_similar_movies():\n",
    "    global similar_movies\n",
    "    cosine_similarities = {}\n",
    "    for feature in feature_vectors.keys():\n",
    "        cosine_sim = cosine_similarity(feature_vectors[feature])\n",
    "        cosine_sim = MinMaxScaler().fit_transform(cosine_sim)\n",
    "\n",
    "        if (feature == 'Plot'):\n",
    "            cosine_sim *= 1.25\n",
    "        \n",
    "        cosine_similarities[feature] = cosine_sim\n",
    "    \n",
    "    cosines = {}\n",
    "    for movie in WATCH_LIST:\n",
    "        for feature in feature_vectors.keys():\n",
    "            if feature not in cosines:\n",
    "                cosines[feature] = []\n",
    "            cosines[feature].append(cosine_similarities[feature][movie])\n",
    "\n",
    "    reccomendations_positions = [[i, 0] for i in range(len(cosines['Actors'][0]))]\n",
    "\n",
    "    means_by_feature = {}\n",
    "    for feature in cosines.keys():\n",
    "        means = calculate_mean(cosines[feature])\n",
    "        means_by_feature[feature] = []\n",
    "        for i in range(len(means)):\n",
    "            means_by_feature[feature].append((i, means[i]))\n",
    "\n",
    "    for feature in means_by_feature.keys():\n",
    "        sorted_recommendations = sorted(means_by_feature[feature], key=lambda r: r[1], reverse=True)\n",
    "        for i in range(len(sorted_recommendations)):\n",
    "            reccomendations_positions[sorted_recommendations[i][0]][1] += i\n",
    "    for movie in WATCH_LIST:\n",
    "        reccomendations_positions[movie][1] = len(reccomendations_positions)\n",
    "    watch_list_recommendations = sorted(reccomendations_positions, key=lambda r: r[1])\n",
    "\n",
    "    filtered = [x for x in watch_list_recommendations if x not in WATCH_LIST]\n",
    "\n",
    "    similar_movies = [r[0] for r in filtered[:MOVIE_COUNT]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# showing movie information\n",
    "\n",
    "To display the recommended movies they are shown in the provided html movie-display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load movies into a dataframe\n",
    "df = pd.read_json('./dataset/imdbdata.json', orient='columns')\n",
    "movies_for_display = []\n",
    "def display_movies():\n",
    "    for i in range(len(similar_movies)):\n",
    "        movies_for_display.append(df.iloc[similar_movies[i]])\n",
    "\n",
    "def html_display():\n",
    "    display(HTML(movie_display.show(movies_for_display)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the jupyter widget, you can fill in up to 10 movies in the text boxed to make a watch list to base the reccomendation on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_watch_list(widgets, count):\n",
    "    MOVIE_COUNT = count\n",
    "    for widget in widgets:\n",
    "        if widget.value != \"\":\n",
    "            WATCH_LIST.append(int(widget.value))\n",
    "\n",
    "text_widgets = []\n",
    "for i in range(10):\n",
    "    text_widget = widgets.Text(\n",
    "        description=f'movie {i+1}:',\n",
    "    )\n",
    "    text_widgets.append(text_widget)\n",
    "\n",
    "recommendation_slider = widgets.IntSlider(\n",
    "    min=1, max=20, step=1, value=10, description=\"Amount of recommendations:\"\n",
    ")\n",
    "\n",
    "# Button to submit the selections\n",
    "submit_button = widgets.Button(description=\"Submit\")\n",
    "\n",
    "# Function to trigger when button is clicked\n",
    "def on_submit_clicked(b):\n",
    "    set_watch_list(widgets = text_widgets, count=recommendation_slider.value)\n",
    "    set_actors_bow()\n",
    "    set_director_bow()\n",
    "    set_title_bow()\n",
    "    set_writers_bow()\n",
    "    set_plot_tf_idf()\n",
    "    get_similar_movies()\n",
    "    display_movies()\n",
    "    html_display()\n",
    "\n",
    "# Attach the button to the callback function\n",
    "submit_button.on_click(on_submit_clicked)\n",
    "\n",
    "# Display the widgets\n",
    "for widget in text_widgets:\n",
    "    display(widget)\n",
    "display(recommendation_slider)\n",
    "display(submit_button)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "assignment-1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
