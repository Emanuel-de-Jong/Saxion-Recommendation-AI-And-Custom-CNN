{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative filtering\n",
    "Emanuel de Jong (495804) - Erik Markvoort (519894)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports\n",
    "\n",
    "the following modules are used for the collaborative filtering assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "from movie_display import movie_display\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from ipywidgets import interact_manual\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "these global variables are used to determine which user the recommendations are based on and how many recommendations should be given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_ID = 1\n",
    "RECOMMENDATION_COUNT = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## similarity user 1 and 2 in cosine, pearson and adjusted cosine\n",
    "\n",
    "to verify a correct calulation of cosine similarities, data is taken from the examples in the slides as a 2D numpy array.\n",
    "user A and B are the users for which we calculate the various cosine similarities between."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_data = np.array([[4.0,0.0,0.0,5.0,1.0,0.0,0.0],[5.0,5.0,4.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,2.0,4.0,5.0,0.0],[0.0,3.0,0.0,0.0,0.0,1.0,3.0]])\n",
    "numpy_data\n",
    "\n",
    "userA = 0\n",
    "userB = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to calculate the standard cosine similarity, first, each item from the two users are "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = np.sum(numpy_data[userA] * numpy_data[userB])\n",
    "b1 = (np.sqrt(np.sum(numpy_data[userA]**2)) * np.sqrt(np.sum(numpy_data[userB]**2)))\n",
    "cosineSimilarity = a1 / b1\n",
    "print(\"regular cosine similarity: \" + str(cosineSimilarity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanA = np.sum(numpy_data[userA]) / np.sum(numpy_data[userA] > 0)\n",
    "pearsonA = numpy_data[userA].copy()\n",
    "pearsonA[numpy_data[userA] > 0] -= meanA\n",
    "meanB = np.sum(numpy_data[userB]) / np.sum(numpy_data[userB] > 0)\n",
    "pearsonB = numpy_data[userB].copy()\n",
    "pearsonB[numpy_data[userB] > 0] -= meanB\n",
    "a2 = np.sum(pearsonA * pearsonB)\n",
    "b2 = (np.sqrt(np.sum(pearsonA**2)) * np.sqrt(np.sum(pearsonB**2)))\n",
    "pearsonSimilarity = a2 / b2\n",
    "print(\"pearson cosine similarity: \" + str(pearsonSimilarity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjustedData = numpy_data.copy()\n",
    "for i in range(0, len(numpy_data[0])):\n",
    "    mean = np.sum(adjustedData[:,i]) / np.sum(adjustedData[:,i] > 0)\n",
    "    adjustedData[adjustedData[:,i] > 0, i] -= mean\n",
    "a3 = np.sum(adjustedData[userA] * adjustedData[userB])\n",
    "b3 = (np.sqrt(np.sum(adjustedData[userA]**2)) * np.sqrt(np.sum(adjustedData[userB]**2)))\n",
    "adjustedCosineSimilarity = a3 / b3\n",
    "print(\"adjusted cosine similarity: \" + str(adjustedCosineSimilarity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is read into a pandas dataframe. Then, the sparse matrix is converted into a 2d-array matrix in order to be able to do the correct calculations on it and each non existing data is converted into a 0.0 float. It is also mapped which index is mapped to which movie title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = pd.read_csv('./dataset/ratings.csv')\n",
    "\n",
    "unique_movie_ids = sorted(csv['movieId'].unique())\n",
    "movie_id_mapping = {movie_id: idx for idx, movie_id in enumerate(unique_movie_ids)}\n",
    "csv['movieId_mapped'] = csv['movieId'].map(movie_id_mapping)\n",
    "\n",
    "reverse_movie_id_mapping = {v: k for k, v in movie_id_mapping.items()}\n",
    "\n",
    "pivot_df = csv.pivot(index='userId', columns='movieId_mapped', values='rating')\n",
    "pivot_df = pivot_df.fillna(0)\n",
    "\n",
    "pivot_df.iloc[:5,:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pandas dataframe is converted into a numpy 2d array to be able to make numpy calculations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_data = pivot_df.to_numpy()\n",
    "numpy_data[:5,:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity calculation methods\n",
    "\n",
    "these methods are to make it possible to use a similarity matrices in multiple locations of the program. Here, we use scikit learn's method to calculate similarities into a matrix. For pearson similarity, the mean of a row's non-zero values is subtracted from each non-zero value in that row, after which the standard cosine similarity is used. For adjusted similarity, a column's non-zero values mean is subtracted from that column's non-zero values, after which standard cosine similarity is calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cosine_similarity(data):\n",
    "    return cosine_similarity(data)\n",
    "\n",
    "def get_pearson_similarity(data):\n",
    "    mean_user_rating = np.zeros(data.shape[0])\n",
    "    for i in range(data.shape[0]):\n",
    "        non_zero_ratings = np.count_nonzero(data[i])\n",
    "        if non_zero_ratings > 0:\n",
    "            mean_user_rating[i] = np.sum(data[i]) / non_zero_ratings\n",
    "\n",
    "    centered_data = data.copy()\n",
    "    for i in range(len(mean_user_rating)):\n",
    "        non_zero_mask = data[i] > 0\n",
    "        centered_data[i][non_zero_mask] -= mean_user_rating[i]\n",
    "\n",
    "    return cosine_similarity(centered_data)\n",
    "\n",
    "def get_adjusted_cosine_similarity(data):\n",
    "    mean_item_rating = np.sum(data, axis=0) / np.count_nonzero(data, axis=0)\n",
    "    adjusted_data = data.copy()\n",
    "    for j in range(len(mean_item_rating)):\n",
    "        non_zero_mask = data[:, j] > 0  \n",
    "        adjusted_data[non_zero_mask, j] -= mean_item_rating[j] \n",
    "    return cosine_similarity(adjusted_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User-user reccomendations\n",
    "\n",
    "In the following method, the cosine similarity matrix chosen by the user is used to find the most similar users to the selected user. then, the highest rated movies among these similar users are given as a recommendation sorted from highest to lowest. This method is used in the eventual program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_user_recommendations():\n",
    "    used_matrix = get_pearson_similarity(numpy_data)\n",
    "    similarities = []\n",
    "    movies_unrated = np.where(numpy_data[USER_ID] == 0.0)[0]\n",
    "\n",
    "    for i in range(0, len(used_matrix[USER_ID])):\n",
    "        if i != USER_ID:\n",
    "            similarities.append((i, used_matrix[USER_ID][i]))\n",
    "\n",
    "    similarities = sorted(similarities, key=lambda r: r[1], reverse=True)\n",
    "    similar_users = [r[0] for r in similarities[:10]]\n",
    "    total_ratings = np.zeros(len(numpy_data[0]))\n",
    "    for user in similar_users:\n",
    "        total_ratings += numpy_data[user]\n",
    "\n",
    "    movie_reccomendations = []\n",
    "    for i in range(0, len(total_ratings)):\n",
    "        if np.isin(i, movies_unrated):\n",
    "            movie_reccomendations.append((i, total_ratings[i]))\n",
    "\n",
    "    movie_reccomendations = sorted(movie_reccomendations, key=lambda r: r[1], reverse=True)\n",
    "\n",
    "    recommendations_user_user = [r[0] for r in movie_reccomendations[:RECOMMENDATION_COUNT]]\n",
    "\n",
    "    recommendations_user_user\n",
    "    return [reverse_movie_id_mapping[movie_mapped_id] for movie_mapped_id in recommendations_user_user]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# validation hit-rate\n",
    "\n",
    "To validate the results of the recommendations given for user-user recommendation, the hit rate method is used. Ahead of the hit-rate method all movies with less than a total of 300 ratings are eliminated to find a more accurate similarity between users. \n",
    "After elimination, a new dataset is made where for each row, the highest value is changed into a 0.0 and the location of this value is saved. \n",
    "Then, for each user, a user-user recommendation is made of 5 movies. if the highest rated movie is in this top-5, it is counted as a hit. The total amount of hits is divided by the amount of users to make the hot-rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hitrate_user_user():\n",
    "    non_zero_counts_cols = np.count_nonzero(numpy_data, axis=0)\n",
    "    filtered_data = numpy_data[:, non_zero_counts_cols >= 300]\n",
    "\n",
    "    max_indices = np.argmax(filtered_data, axis=1)\n",
    "    new_data = np.copy(filtered_data)\n",
    "\n",
    "    for i in range(filtered_data.shape[0]):\n",
    "        max_index = np.argmax(filtered_data[i])\n",
    "        new_data[i, max_index] = 0.0\n",
    "    new_pearson = similarity_matrix_function(new_data)\n",
    "\n",
    "    hitrate_space = 5\n",
    "    tries = len(numpy_data[:,0])\n",
    "    hits = 0\n",
    "\n",
    "    for i in range(tries):\n",
    "        similarities = []\n",
    "        movies_unrated = np.where(transposed_data[:,USER_ID] == 0)[0]\n",
    "        for j in range(0, len(new_pearson[i])):\n",
    "            if j != tries:\n",
    "                similarities.append((j, new_pearson[i][j]))\n",
    "        similarities = sorted(similarities, key=lambda r: r[1], reverse=True)\n",
    "        similar_users = [r[0] for r in similarities[:10]]\n",
    "        total_ratings = np.zeros(len(new_data[0]))\n",
    "        for user in similar_users:\n",
    "            total_ratings += new_data[user]\n",
    "        movie_reccomendations = []\n",
    "        for k in range(0, len(total_ratings)):\n",
    "            movie_reccomendations.append((k, total_ratings[k]))\n",
    "        movie_reccomendations = sorted(movie_reccomendations, key=lambda r: r[1], reverse=True)\n",
    "        reccomendations_movies = [r[0] for r in movie_reccomendations[:hitrate_space]]\n",
    "        if np.isin(max_indices[i], reccomendations_movies):\n",
    "            hits += 1\n",
    "    hitrate = hits / tries\n",
    "    return hitrate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item-item recommendations\n",
    "\n",
    "for item-item recommendation, a minimum amount of a rating is made to take into account only movies with a rating above 3.5 when making recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_USER_RATING = 3.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to make item-item recommendations, the data is transposed into a numpy 2d array where rows are movies and columns are users. This is to make it possible to make a similarity matrix between movies instead of users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "transposed_data = np.transpose(numpy_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following method is used to find the highest rated movies for the selected user. This is for display purposes when showing the top rated movies next to the top reccomended movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_movies_with_high_rating():\n",
    "    # Get indicies of movies the user has rated higher than or exqual to MIN_USER_RATING\n",
    "    user_movies_with_high_rating = np.where(transposed_data[:, USER_ID] >= MIN_USER_RATING)[0]\n",
    "    # Get the ratings of those indicies\n",
    "    movie_ratings = transposed_data[user_movies_with_high_rating, USER_ID]\n",
    "    # Get the indicies of the ratings sorted by highest rating\n",
    "    sorted_indices = np.argsort(-movie_ratings)\n",
    "    # Sort the indicies of the movies by highest user rating with sorted_indices\n",
    "    return user_movies_with_high_rating[sorted_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following method, item-item recommendations are given. To make item-item recommendations, the indexes are saved for both unrated movies(0.0) and highly rated movies(> 3.5). The similarity is calculated between the rated and unrated movies, then, for the 2 most similar movies, a calculation is made to make up the expected rating((similarity1 * rating1 + similarity2 * rating2) / (similarity1 * similarity2)). \n",
    "For the user, an expected rating is calculated for each unrated movie. Then, the unrated movies with the highest expected ratings are given as the item-item recommendation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_highest_rated_unwatched_movies():  \n",
    "    movies_rated = np.where(transposed_data[:, USER_ID] >= MIN_USER_RATING)[0]\n",
    "\n",
    "    movies_unrated = np.where(transposed_data[:,USER_ID] == 0)[0]\n",
    "    movie_ex_ratings = []\n",
    "    for movie in movies_unrated:\n",
    "        similarities = []\n",
    "        for rated in movies_rated:\n",
    "            similarities.append([rated, used_matrix[movie][rated]])\n",
    "        similarities = sorted(similarities, key=lambda r: r[1], reverse=True)\n",
    "        ex_rating = ((transposed_data[:,USER_ID][similarities[0][0]] * similarities[0][1]) + (transposed_data[:,USER_ID][similarities[1][0]] * similarities[1][1])) / (similarities[1][1] + similarities[0][1])\n",
    "        movie_ex_ratings.append([movie, ex_rating])\n",
    "    movie_ex_ratings = sorted(movie_ex_ratings, key=lambda r: r[1], reverse=True)\n",
    "    reccomended_unrated_movies = []\n",
    "    for i in range(RECOMMENDATION_COUNT):\n",
    "        reccomended_unrated_movies.append(movie_ex_ratings[i][0])\n",
    "    \n",
    "    return [reverse_movie_id_mapping[movie_mapped_id] for movie_mapped_id in reccomended_unrated_movies]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To validate the results of the recommendations given for item-item recommendation, the hit rate method is used. Ahead of the hit-rate method all users with less than a total of 500 ratings are eliminated to find a more accurate similarity between items. \n",
    "After elimination, a new dataset is made where for each row, the highest value is changed into a 0.0 and the location of this value is saved. \n",
    "Then, for each user, a user-user recommendation is made of 20 movies. If the highest rated movie is in this top-20, it is counted as a hit. The total amount of hits is divided by the amount of users to make the hit-rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hitrate_item_item():    \n",
    "    non_zero_counts = np.count_nonzero(numpy_data, axis=1)\n",
    "    filtered_data = numpy_data[non_zero_counts >= 500]\n",
    "\n",
    "    max_indices = np.argmax(filtered_data, axis=1)\n",
    "    new_data = np.copy(filtered_data)\n",
    "    for i in range(new_data.shape[0]):\n",
    "        new_data[i, max_indices[i]] = 0.0\n",
    "\n",
    "    transposed_new = np.transpose(new_data)\n",
    "\n",
    "    used_matrix = similarity_matrix_function(transposed_new)\n",
    "\n",
    "    hitrate_space = 20\n",
    "    tries = len(transposed_new[0])\n",
    "    hits = 0\n",
    "    for i in range(tries):\n",
    "        USER_ID = i\n",
    "        \n",
    "        movies_rated = np.where(transposed_new[:, USER_ID] >= MIN_USER_RATING)[0]\n",
    "\n",
    "        movies_unrated = np.where(transposed_new[:,USER_ID] == 0)[0]\n",
    "        movie_ex_ratings = []\n",
    "        for movie in movies_unrated:\n",
    "            similarities = []\n",
    "            for rated in movies_rated:\n",
    "                similarities.append([rated, used_matrix[movie][rated]])\n",
    "            similarities = sorted(similarities, key=lambda r: r[1], reverse=True)\n",
    "            ex_rating = ((transposed_new[:,USER_ID][similarities[0][0]] * similarities[0][1]) + (transposed_new[:,USER_ID][similarities[1][0]] * similarities[1][1])) / (similarities[1][1] + similarities[0][1])\n",
    "            movie_ex_ratings.append([movie, ex_rating])\n",
    "        movie_ex_ratings = sorted(movie_ex_ratings, key=lambda r: r[1], reverse=True)\n",
    "        reccomended_unrated_movies = []\n",
    "        for i in range(hitrate_space):\n",
    "            reccomended_unrated_movies.append(movie_ex_ratings[i][0])\n",
    "        recommendations_movies = reccomended_unrated_movies\n",
    "\n",
    "        if np.isin(max_indices[i], recommendations_movies):\n",
    "            hits += 1\n",
    "\n",
    "    hitrate = hits / tries\n",
    "    return hitrate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Program\n",
    "\n",
    "In the program, a user can fill in the parameters for how to make a recommendation.\n",
    "\n",
    "this method is to convert user input into integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_from_str(value, max_value):\n",
    "    for i in range(1, max_value + 1):\n",
    "        if str(i) in value:\n",
    "            return i\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the parameters, a standard value is given in the case the user gives no input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendation_method = \"Item-Item\"\n",
    "similarity_matrix_method = \"Pearson\"\n",
    "similarity_matrix_function = get_pearson_similarity\n",
    "RECOMMENDATION_COUNT = 5\n",
    "USER_ID = 5\n",
    "hitrate_bool = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The indexes in ratings.csv are not directly related to the displayable data in imdbdata.json. These methods help with linking the movie reccomendations to imdb data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "links_data = pd.read_csv('./dataset/links.csv')\n",
    "imdb_data = pd.read_json('./dataset/imdbdata.json')\n",
    "\n",
    "imdb_data['imdbId'] = imdb_data['imdbId'].astype(int)\n",
    "\n",
    "def movies_to_imdb(movies):\n",
    "    imdb_ids = []\n",
    "    for movie_id in movies:\n",
    "        link = links_data[links_data['movieId'] == movie_id]\n",
    "        if not link.empty:\n",
    "            imdb_id = link.iloc[0]['imdbId']\n",
    "            imdb_ids.append(imdb_id)\n",
    "\n",
    "    imdb_movies = []\n",
    "    for imdb_id in imdb_ids:\n",
    "        imdb_movie = imdb_data[imdb_data['imdbId'] == imdb_id]\n",
    "        if not imdb_movie.empty:\n",
    "            imdb_movies.append(imdb_movie.iloc[0])\n",
    "    \n",
    "    return imdb_movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These methods are to display movies with the provided html movie displayer, firstly, for the users highly rated movies and secondly for movies recommended to the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_high_rated():\n",
    "    user_movies_with_high_rating = get_user_movies_with_high_rating()\n",
    "    user_movies_with_high_rating = [reverse_movie_id_mapping[movie_mapped_id] for movie_mapped_id in user_movies_with_high_rating[:RECOMMENDATION_COUNT]]\n",
    "\n",
    "    movies_to_show = movies_to_imdb(user_movies_with_high_rating)\n",
    "    \n",
    "    print(\"Movies rated highly by the user:\")\n",
    "    display(HTML(movie_display.show(movies_to_show)))\n",
    "\n",
    "def display_final_result():\n",
    "    movies_to_show = movies_to_imdb(recommendations)\n",
    "\n",
    "    print(\"Movies reccomended\")\n",
    "    display(HTML(movie_display.show(movies_to_show)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following widget, a user can fill in the desired recommendation method, similarity matrix, recommendation count, user and if they want to see a hitrate. When submit it clicked, it will display the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit_all(method, similarity, recommendation_count, user_id, hitrate):\n",
    "    global recommendation_method, similarity_matrix_function, used_matrix, recommendations\n",
    "    global RECOMMENDATION_COUNT, USER_ID, hitrate_bool\n",
    "\n",
    "    RECOMMENDATION_COUNT = recommendation_count\n",
    "    USER_ID = user_id\n",
    "    \n",
    "    # Set recommendation method and data\n",
    "    if method == \"User-User\":\n",
    "        recommendation_method = method\n",
    "        data = numpy_data\n",
    "    elif method == \"Item-Item\":\n",
    "        recommendation_method = method\n",
    "        data = transposed_data\n",
    "    \n",
    "    # Set similarity matrix function\n",
    "    if similarity == \"Cosine\":\n",
    "        similarity_matrix_function = get_cosine_similarity\n",
    "    elif similarity == \"Pearson\":\n",
    "        similarity_matrix_function = get_pearson_similarity\n",
    "    elif similarity == \"Adjusted\":\n",
    "        similarity_matrix_function = get_adjusted_cosine_similarity\n",
    "    \n",
    "    # Calculate similarity matrix\n",
    "    used_matrix = similarity_matrix_function(data)\n",
    "    \n",
    "    # Generate recommendations based on method\n",
    "    if recommendation_method == \"User-User\":\n",
    "        recommendations = get_user_user_recommendations()\n",
    "    elif recommendation_method == \"Item-Item\":\n",
    "        recommendations = get_user_highest_rated_unwatched_movies()\n",
    "    \n",
    "    # Set other parameters\n",
    "    hitrate_bool = 1 if hitrate == \"Yes\" else 0\n",
    "    \n",
    "    # Output the selections\n",
    "    print(f\"Recommendation Method: {recommendation_method}\")\n",
    "    print(f\"Similarity Method: {similarity}\")\n",
    "    print(f\"Recommendation Count: {RECOMMENDATION_COUNT}\")\n",
    "    print(f\"User ID: {USER_ID}\")\n",
    "    print(f\"Hitrate Evaluation: {hitrate}\")\n",
    "    print(f\"Similarity Matrix: {similarity}\")\n",
    "\n",
    "    if hitrate_bool == 1:\n",
    "        if recommendation_method == \"User-User\":\n",
    "            print(\"Hit-rate user-user recommendation: \" + str(hitrate_user_user()))\n",
    "        elif recommendation_method == \"Item-Item\":\n",
    "            print(\"Hit-rate item-item recommendation: \" + str(hitrate_item_item()))\n",
    "\n",
    "# Create widgets for all interactions\n",
    "method_dropdown = widgets.Dropdown(\n",
    "    options=[\"User-User\", \"Item-Item\"],\n",
    "    description=\"Method:\"\n",
    ")\n",
    "\n",
    "similarity_dropdown = widgets.Dropdown(\n",
    "    options=[\"Cosine\", \"Pearson\", \"Adjusted\"],\n",
    "    description=\"Similarity:\"\n",
    ")\n",
    "\n",
    "recommendation_slider = widgets.IntSlider(\n",
    "    min=1, max=20, step=1, value=10, description=\"Count:\"\n",
    ")\n",
    "\n",
    "user_slider = widgets.IntSlider(\n",
    "    min=0, max=500, step=1, value=10, description=\"User ID:\"\n",
    ")\n",
    "\n",
    "hitrate_dropdown = widgets.Dropdown(\n",
    "    options=[\"No\", \"Yes\"],\n",
    "    description=\"Hitrate:\"\n",
    ")\n",
    "\n",
    "# Button to submit the selections\n",
    "submit_button = widgets.Button(description=\"Submit\")\n",
    "\n",
    "# Function to trigger when button is clicked\n",
    "def on_submit_clicked(b):\n",
    "    submit_all(\n",
    "        method=method_dropdown.value,\n",
    "        similarity=similarity_dropdown.value,\n",
    "        recommendation_count=recommendation_slider.value,\n",
    "        user_id=user_slider.value,\n",
    "        hitrate=hitrate_dropdown.value\n",
    "    )\n",
    "    display_high_rated()\n",
    "    display_final_result()\n",
    "\n",
    "\n",
    "# Attach the button to the callback function\n",
    "submit_button.on_click(on_submit_clicked)\n",
    "\n",
    "# Display the widgets\n",
    "display(method_dropdown, similarity_dropdown, recommendation_slider, user_slider, hitrate_dropdown, submit_button)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "firstenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
